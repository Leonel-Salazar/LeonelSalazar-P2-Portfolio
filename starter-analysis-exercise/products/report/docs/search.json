[
  {
    "objectID": "manuscript_final.html",
    "href": "manuscript_final.html",
    "title": "Untitled",
    "section": "",
    "text": "The structure below is one possible setup for a data analysis project (including the course project). For a manuscript, adjust as needed. You don’t need to have exactly these sections, but the content covering those sections should be addressed.\nThis uses MS Word as output format. See here for more information. You can switch to other formats, like html or pdf. See the Quarto documentation for other formats.\nWarning: package 'here' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'scales' was built under R version 4.3.2"
  },
  {
    "objectID": "manuscript_final.html#description-of-data-and-data-source",
    "href": "manuscript_final.html#description-of-data-and-data-source",
    "title": "Untitled",
    "section": "Description of data and data source",
    "text": "Description of data and data source\nBee colonies maintained by beekeepers are considered livestock by the USDA due to their ability to produce honey, a consumable food item, and their essential role in assisting farmers with pollination crop seasons. Given the importance of bee colonies in agriculture, it was logical to source data from the following two authoritative websites: 1. USDA National Agricultural Statistics Service (NASS): This site provides comprehensive agricultural data, including statistics on honey production and colony health. 2. Bee Informed Partnership: This site offers detailed insights and research on bee colony management and health, contributing valuable information on the status and trends of bee populations. Index Catalog // USDA Economics, Statistics and Market Information System. (n.d.-a). https://usda.library.cornell.edu/catalog?f%5Bkeywords_sim%5D%5B%5D=honey+bees&locale=en\nUSDA - National Agricultural Statistics Service - Surveys - honey bee surveys and reports. (n.d.). https://www.nass.usda.gov/Surveys/Guide_to_NASS_Surveys/Bee_and_Honey/"
  },
  {
    "objectID": "manuscript_final.html#questionshypotheses-to-be-addressed",
    "href": "manuscript_final.html#questionshypotheses-to-be-addressed",
    "title": "Untitled",
    "section": "Questions/Hypotheses to be addressed",
    "text": "Questions/Hypotheses to be addressed\nHypothesis: “The negative impacts of mites, bacterium, and global warming have detrimental effects on honeybee colonies in the United States and Texas, which in turn will lead to a decline in honey production and negatively impact food production.” This hypothesis can be tested and validated through a visualization of outcomes using R, demonstrating the relationship between these factors and their effects on honeybee colonies.\nBacterium Infection Foul Brood.\n\nDead bees resulting from extreme heat found in hive.\n\nTo cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the bibtex file specified in the YAML header above and have the right bibtex key. Then you can include like this:\nExamples of reproducible research projects can for instance be found in [@mckay2020; @mckay2020a]."
  },
  {
    "objectID": "manuscript_final.html#schematic-of-workflow",
    "href": "manuscript_final.html#schematic-of-workflow",
    "title": "Untitled",
    "section": "Schematic of workflow",
    "text": "Schematic of workflow\nSometimes you might want to show a schematic diagram/figure that was not created with code (if you can do it with code, do it). ?@fig-schematic is an example of some - completely random/unrelated - schematic that was generated with Biorender. We store those figures in the assets folder.\n\n#knitr::include_graphics(here(\"assets\",\"antigen-recognition.png\"))"
  },
  {
    "objectID": "manuscript_final.html#data-aquisition",
    "href": "manuscript_final.html#data-aquisition",
    "title": "Untitled",
    "section": "Data aquisition",
    "text": "Data aquisition\nWe got our data from the United States Department of Agriculture (USDA)."
  },
  {
    "objectID": "manuscript_final.html#data-import-and-cleaning",
    "href": "manuscript_final.html#data-import-and-cleaning",
    "title": "Untitled",
    "section": "Data import and cleaning",
    "text": "Data import and cleaning\nWe decided to clean out our data from a few different datasets. We had to remove blank spaces and columns that were not pertinent to our analysis. We then filtered out other observations that did not directly deal with the data we are exploring. We are looking for cause of death to bee colonies and how they are affected by mites and climate change so we wanted to single out data that represented the losses so we can explore the different states by year and determine how the colonies were affected.\n\nlibrary(readxl)\nlibrary(tidyverse)\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n✔ readr     2.1.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ purrr::map()        masks maps::map()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(knitr)\n\n\nlibrary(here)\n\nhere()\n\n[1] \"C:/Users/Leonel/Desktop/MSDA/MS Data Analytics/Current Class/DA 6833/Practicum 2 Github/leonelsalazar-P2-portfolio/starter-analysis-exercise\"\n\n# Read the CSV file\ndata &lt;- read.csv(here(\"Databystate.csv\"))\n\n\n# Select all columns except 3, 6, and 9\nData_Clean &lt;- dplyr::select(data, -c(3, 6, 9))\n\n\n# Output cleaned data file to a csv file.\n\nwrite.csv(Data_Clean, \"Data_Clean.csv\", row.names = FALSE)\n\n#write.csv(Data_Clean, \"C:/Users/ecruz/OneDrive/Documents/UTSA - Data Science Program/Semester Classes/Practicum II Repository/P2-Practicum-II-Portfolio-EdwardCruz/docs/Databystate_Clean.csv\")\n\n\n# Assuming your data frame is named \"data\"\n\n# Filter for rows where \"Loss\" or \"Deadout\" is present in any column (case-insensitive)\n\nlibrary(stringr)  # Load stringr package for regular expressions\ndata_filtered &lt;- Data_Clean[rowSums(sapply(data, grepl, pattern = c(\"Loss\"), ignore.case = TRUE)) &gt; 0, ]\n\n\n# Output cleaned data file to a csv file.\n\nwrite.csv(data_filtered, \"Data_Filtered.csv\", row.names = FALSE)\n\n#write.csv(Data_Clean, \"C:/Users/ecruz/OneDrive/Documents/UTSA - Data Science Program/Semester Classes/Practicum II Repository/P2-Practicum-II-Portfolio-EdwardCruz/docs/Databystate_Filtered.csv\")\n\n\n# View data str to see what class they are.\n\nstr(data_filtered)\n\n'data.frame':   718 obs. of  6 variables:\n $ Year      : int  2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 ...\n $ Period    : chr  \"JAN THRU MAR\" \"JAN THRU MAR\" \"JAN THRU MAR\" \"JAN THRU MAR\" ...\n $ State     : chr  \"ALABAMA\" \"ARIZONA\" \"ARKANSAS\" \"CALIFORNIA\" ...\n $ State.ANSI: int  1 4 5 6 8 9 12 13 15 16 ...\n $ Data.Item : chr  \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" ...\n $ Value     : chr  \"250\" \"2,600\" \"180\" \"19,000\" ...\n\n\n\nstr(data_filtered)\n\n'data.frame':   718 obs. of  6 variables:\n $ Year      : int  2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 ...\n $ Period    : chr  \"JAN THRU MAR\" \"JAN THRU MAR\" \"JAN THRU MAR\" \"JAN THRU MAR\" ...\n $ State     : chr  \"ALABAMA\" \"ARIZONA\" \"ARKANSAS\" \"CALIFORNIA\" ...\n $ State.ANSI: int  1 4 5 6 8 9 12 13 15 16 ...\n $ Data.Item : chr  \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" ...\n $ Value     : chr  \"250\" \"2,600\" \"180\" \"19,000\" ...\n\n# Load the dataset\ndata_filtered &lt;- read.csv(here::here(\"Data_Filtered.csv\"), stringsAsFactors = FALSE)\n\n# Convert 'Value' to numeric\ndata_filtered$Value &lt;- as.numeric(gsub(\",\", \"\", data_filtered$Value))\n\n# Handle missing values by replacing NAs with the median value\ndata_filtered$Value[is.na(data_filtered$Value)] &lt;- median(data_filtered$Value, na.rm = TRUE)\n\n# Boxplot of Value by Year and Data.Item\nggplot(data_filtered, aes(x = factor(Year), y = Value, fill = Data.Item)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_y_continuous(labels = comma) +\n  labs(title = \"Boxplot of Value by Year and Data.Item\", x = \"Year\", y = \"Value\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Scatterplot of Value by State.ANSI\nggplot(data_filtered, aes(x = State.ANSI, y = Value, color = factor(Year))) +\n  geom_point() +\n  labs(title = \"Scatterplot of Value by State.ANSI\", x = \"State.ANSI\", y = \"Value\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load necessary library\nlibrary(scales)\n\n\n# Assuming data_filtered is already loaded and has the required columns\n\n# Create the plot\np &lt;- ggplot(data_filtered, aes(x = Period, y = Value, fill = Data.Item)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_y_continuous(labels = comma) +\n  labs(title = \"Boxplot of Value by Period and Data.Item\", x = \"Period\", y = \"Value\")\n\n# Print the plot\nprint(p)\n\n\n\n\n\n\n\n\n************** Leo provided additional code below and works perfectly********************\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(reshape2)\n\nWarning: package 'reshape2' was built under R version 4.3.3\n\n\n\nAttaching package: 'reshape2'\n\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n\nlibrary(cluster)\n\n\nAttaching package: 'cluster'\n\n\nThe following object is masked from 'package:maps':\n\n    votes.repub\n\nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nlibrary(factoextra)\n\nWarning: package 'factoextra' was built under R version 4.3.3\n\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\nWarning: package 'rpart.plot' was built under R version 4.3.3\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.3.3\n\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\nlibrary(e1071)\n\nWarning: package 'e1071' was built under R version 4.3.3\n\n\n\n# Load your dataset\n# Assuming your data frame is named 'data_hcny'\n\ndata_hcny &lt;- read.csv(here(\"hcny_CleanDraft.csv\"))\n\n\ndata_clean &lt;- na.omit(data_hcny)\n\n\n# Descriptive Statistics\nprint(\"Descriptive Statistics:\")\n\n[1] \"Descriptive Statistics:\"\n\nsummary(data_clean)\n\n    state            varroa_mites    other_pests       disease      \n Length:11          Min.   : 8.00   Min.   : 1.70   Min.   : 0.100  \n Class :character   1st Qu.:13.45   1st Qu.: 3.20   1st Qu.: 0.750  \n Mode  :character   Median :26.80   Median : 6.40   Median : 1.000  \n                    Mean   :32.41   Mean   :11.55   Mean   : 6.718  \n                    3rd Qu.:48.85   3rd Qu.:11.85   3rd Qu.: 4.600  \n                    Max.   :67.20   Max.   :42.30   Max.   :47.800  \n   pesticides        other          unknown      \n Min.   : 0.50   Min.   : 0.50   Min.   : 1.100  \n 1st Qu.: 1.70   1st Qu.: 1.05   1st Qu.: 2.900  \n Median : 5.70   Median : 3.40   Median : 4.400  \n Mean   :10.34   Mean   :10.51   Mean   : 8.718  \n 3rd Qu.:11.30   3rd Qu.:11.35   3rd Qu.: 8.100  \n Max.   :49.20   Max.   :48.10   Max.   :46.800  \n\n\n\n# Visualizations\n\n# Bar Plot for varroa_mites by State\nggplot(data_clean, aes(x = state, y = varroa_mites)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Varroa Mites by State\", y = \"Percentage\", x = \"State\")\n\n\n\n\n\n\n\n\n\n# Stacked Bar Plot\ndata_long &lt;- data_clean %&gt;%\n  gather(key = \"factor\", value = \"percentage\", -state)\n\nggplot(data_long, aes(x = state, y = percentage, fill = factor)) +\n  geom_bar(stat = \"identity\") +\n theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Factors Affecting Bees by State\", y = \"Percentage\", x = \"State\")\n\n\n\n\n\n\n\n\n\n# Heatmap\ndata_melt &lt;- melt(data_clean, id.vars = \"state\")\n\nggplot(data_melt, aes(x = variable, y = state, fill = value)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"red\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Heatmap of Factors Affecting Bees\", y = \"State\", x = \"Factor\")\n\n\n\n\n\n\n\n\n\n# Pie Chart for the United States\nus_data &lt;- data_clean %&gt;%\n  filter(state == \"United States\") %&gt;%\n  dplyr::select(-state) %&gt;%\n  gather(key = \"factor\", value = \"percentage\")\n\nggplot(us_data, aes(x = \"\", y = percentage, fill = factor)) +\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\") +\n  theme_void() +\n  labs(title = \"Distribution of Factors Affecting Bees in the United States\")\n\n\n\n\n\n\n\n\n\n# Correlation Analysis\ncor_data &lt;- cor(data_clean[,-1])\nprint(\"Correlation Matrix:\")\n\n[1] \"Correlation Matrix:\"\n\nprint(cor_data)\n\n             varroa_mites other_pests   disease pesticides     other    unknown\nvarroa_mites    1.0000000  0.62115999 0.5907042 0.65228365 0.6085037 0.55340334\nother_pests     0.6211600  1.00000000 0.1180091 0.06810399 0.3449221 0.05806591\ndisease         0.5907042  0.11800909 1.0000000 0.90369098 0.9194785 0.97833233\npesticides      0.6522836  0.06810399 0.9036910 1.00000000 0.8235853 0.86362322\nother           0.6085037  0.34492207 0.9194785 0.82358532 1.0000000 0.86993151\nunknown         0.5534033  0.05806591 0.9783323 0.86362322 0.8699315 1.00000000\n\n\n\n# Assumption Checks for Descriptive Analysis\nprint(\"Assumption Checks:\")\n\n[1] \"Assumption Checks:\"\n\n\n\n# Normality check\nshapiro_results &lt;- lapply(data_clean[-1], function(column) shapiro.test(column))\nprint(\"Shapiro-Wilk Test for Normality:\")\n\n[1] \"Shapiro-Wilk Test for Normality:\"\n\nprint(shapiro_results)\n\n$varroa_mites\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.87839, p-value = 0.09925\n\n\n$other_pests\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.72499, p-value = 0.0009831\n\n\n$disease\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.51395, p-value = 2.235e-06\n\n\n$pesticides\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.70512, p-value = 0.0005444\n\n\n$other\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.70797, p-value = 0.0005924\n\n\n$unknown\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.55542, p-value = 7.156e-06\n\n\n\n# Homogeneity of variances\n\nlevene_results &lt;- leveneTest(varroa_mites ~ state, data = data_clean)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\nprint(\"Levene's Test for Homogeneity of Variances:\")\n\n[1] \"Levene's Test for Homogeneity of Variances:\"\n\nprint(levene_results)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup 10     NaN    NaN\n       0               \n\n\n\n# Cluster Analysis\ndata_cluster &lt;- data_clean %&gt;%\n  filter(state != \"United States\") %&gt;%\n  dplyr::select(-state)\n\nhc &lt;- hclust(dist(data_cluster), method = \"complete\")\nplot(hc, labels = data_clean$state[data_clean$state != \"United States\"], main = \"Hierarchical Clustering of States\")\n\n\n\n\n\n\n\n\n\n# Principal Component Analysis (PCA)\ndata_pca &lt;- data_clean %&gt;%\n  filter(state != \"United States\") %&gt;%\n  dplyr::select(-state) %&gt;%\n  scale()\n\n\npca_result &lt;- prcomp(data_pca, center = TRUE, scale. = TRUE)\nsummary(pca_result)\n\nImportance of components:\n                          PC1    PC2    PC3     PC4     PC5     PC6\nStandard deviation     2.0647 1.1246 0.5666 0.34369 0.15432 0.09672\nProportion of Variance 0.7105 0.2108 0.0535 0.01969 0.00397 0.00156\nCumulative Proportion  0.7105 0.9213 0.9748 0.99447 0.99844 1.00000\n\n\n\nfviz_pca_var(pca_result, col.var = \"contrib\", gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"))\n\n\n\n\n\n\n\n\n\n# Support Vector Machine (SVM)\nsvm_model &lt;- svm(varroa_mites ~ other_pests + disease + pesticides + other + unknown, data = data_clean)\nsummary(svm_model)\n\n\nCall:\nsvm(formula = varroa_mites ~ other_pests + disease + pesticides + \n    other + unknown, data = data_clean)\n\n\nParameters:\n   SVM-Type:  eps-regression \n SVM-Kernel:  radial \n       cost:  1 \n      gamma:  0.2 \n    epsilon:  0.1 \n\n\nNumber of Support Vectors:  10\n\n\n\n# Assuming predictions and data_clean$varroa_mites are already created\n\n# Example data\ndata_clean &lt;- data.frame(\n  varroa_mites = c(5, 10, 15, 20),\n  other_variable = c(2, 4, 6, 8)\n)\n\n# Fit a linear model\nmodel &lt;- lm(varroa_mites ~ other_variable, data = data_clean)\n\n# Generate predictions\npredictions &lt;- predict(model, newdata = data_clean)\n\n\n# Plot the data\nplot(predictions, data_clean$varroa_mites, \n     xlab = \"Predictions\", \n     ylab = \"Varroa Mites\", \n     main = \"Predictions vs Varroa Mites\",\n     las = 1, # makes y-axis labels horizontal\n     cex.lab = 1.2, # increases axis labels size\n     cex.axis = 1.2) # increases tick labels size\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Write the cleaned data to a new CSV file\n\n\n# Assuming your dataset is named data_hcny\ndata_hcny_clean &lt;- data_hcny %&gt;% drop_na()\n\n\nwrite.csv(data_hcny_clean, here(\"hcnydata_cleaned.csv\"), row.names = FALSE)\n\nVarroa Mite"
  },
  {
    "objectID": "manuscript_final.html#statistical-analysis",
    "href": "manuscript_final.html#statistical-analysis",
    "title": "Untitled",
    "section": "Statistical analysis",
    "text": "Statistical analysis\nExplain anything related to your statistical analyses."
  },
  {
    "objectID": "manuscript_final.html#exploratorydescriptive-analysis",
    "href": "manuscript_final.html#exploratorydescriptive-analysis",
    "title": "Untitled",
    "section": "Exploratory/Descriptive analysis",
    "text": "Exploratory/Descriptive analysis\nUse a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.\n?@tbl-summarytable shows a summary of the data.\nNote the loading of the data providing a relative path using the ../../ notation. (Two dots means a folder up). You never want to specify an absolute path like C:\\ahandel\\myproject\\results\\ because if you share this with someone, it won’t work for them since they don’t have that path. You can also use the here R package to create paths. See examples of that below. I generally recommend the here package."
  },
  {
    "objectID": "manuscript_final.html#summary-and-interpretation",
    "href": "manuscript_final.html#summary-and-interpretation",
    "title": "Untitled",
    "section": "Summary and Interpretation",
    "text": "Summary and Interpretation\nSummarize what you did, what you found and what it means."
  },
  {
    "objectID": "manuscript_final.html#strengths-and-limitations",
    "href": "manuscript_final.html#strengths-and-limitations",
    "title": "Untitled",
    "section": "Strengths and Limitations",
    "text": "Strengths and Limitations\nDiscuss what you perceive as strengths and limitations of your analysis."
  },
  {
    "objectID": "manuscript_final.html#conclusions",
    "href": "manuscript_final.html#conclusions",
    "title": "Untitled",
    "section": "Conclusions",
    "text": "Conclusions\nWhat are the main take-home messages?\nInclude citations in your Rmd file using bibtex, the list of references will automatically be placed at the end"
  },
  {
    "objectID": "manuscript_final-2.html",
    "href": "manuscript_final-2.html",
    "title": "Untitled",
    "section": "",
    "text": "The structure below is one possible setup for a data analysis project (including the course project). For a manuscript, adjust as needed. You don’t need to have exactly these sections, but the content covering those sections should be addressed.\nThis uses MS Word as output format. See here for more information. You can switch to other formats, like html or pdf. See the Quarto documentation for other formats.\nWarning: package 'here' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'scales' was built under R version 4.3.2"
  },
  {
    "objectID": "manuscript_final-2.html#description-of-data-and-data-source",
    "href": "manuscript_final-2.html#description-of-data-and-data-source",
    "title": "Untitled",
    "section": "Description of data and data source",
    "text": "Description of data and data source\nBee colonies maintained by beekeepers are considered livestock by the USDA due to their ability to produce honey, a consumable food item, and their essential role in assisting farmers with pollination crop seasons. Given the importance of bee colonies in agriculture, it was logical to source data from the following two authoritative websites: 1. USDA National Agricultural Statistics Service (NASS): This site provides comprehensive agricultural data, including statistics on honey production and colony health. 2. Bee Informed Partnership: This site offers detailed insights and research on bee colony management and health, contributing valuable information on the status and trends of bee populations. Index Catalog // USDA Economics, Statistics and Market Information System. (n.d.-a). https://usda.library.cornell.edu/catalog?f%5Bkeywords_sim%5D%5B%5D=honey+bees&locale=en\nUSDA - National Agricultural Statistics Service - Surveys - honey bee surveys and reports. (n.d.). https://www.nass.usda.gov/Surveys/Guide_to_NASS_Surveys/Bee_and_Honey/"
  },
  {
    "objectID": "manuscript_final-2.html#questionshypotheses-to-be-addressed",
    "href": "manuscript_final-2.html#questionshypotheses-to-be-addressed",
    "title": "Untitled",
    "section": "Questions/Hypotheses to be addressed",
    "text": "Questions/Hypotheses to be addressed\nHypothesis: “The negative impacts of mites, bacterium, and global warming have detrimental effects on honeybee colonies in the United States and Texas, which in turn will lead to a decline in honey production and negatively impact food production.” This hypothesis can be tested and validated through a visualization of outcomes using R, demonstrating the relationship between these factors and their effects on honeybee colonies.\nBacterium Infection Foul Brood.\n\nDead bees resulting from extreme heat found in hive.\n\nTo cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the bibtex file specified in the YAML header above and have the right bibtex key. Then you can include like this:\nExamples of reproducible research projects can for instance be found in [@mckay2020; @mckay2020a]."
  },
  {
    "objectID": "manuscript_final-2.html#schematic-of-workflow",
    "href": "manuscript_final-2.html#schematic-of-workflow",
    "title": "Untitled",
    "section": "Schematic of workflow",
    "text": "Schematic of workflow\nSometimes you might want to show a schematic diagram/figure that was not created with code (if you can do it with code, do it). ?@fig-schematic is an example of some - completely random/unrelated - schematic that was generated with Biorender. We store those figures in the assets folder.\n\n#knitr::include_graphics(here(\"assets\",\"antigen-recognition.png\"))"
  },
  {
    "objectID": "manuscript_final-2.html#data-aquisition",
    "href": "manuscript_final-2.html#data-aquisition",
    "title": "Untitled",
    "section": "Data aquisition",
    "text": "Data aquisition\nWe got our data from the United States Department of Agriculture (USDA)."
  },
  {
    "objectID": "manuscript_final-2.html#data-import-and-cleaning",
    "href": "manuscript_final-2.html#data-import-and-cleaning",
    "title": "Untitled",
    "section": "Data import and cleaning",
    "text": "Data import and cleaning\nWe decided to clean out our data from a few different datasets. We had to remove blank spaces and columns that were not pertinent to our analysis. We then filtered out other observations that did not directly deal with the data we are exploring. We are looking for cause of death to bee colonies and how they are affected by mites and climate change so we wanted to single out data that represented the losses so we can explore the different states by year and determine how the colonies were affected.\n\nlibrary(readxl)\nlibrary(tidyverse)\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n✔ readr     2.1.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ purrr::map()        masks maps::map()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(knitr)\n\n\nlibrary(here)\n\n#remove.packages(\"here\")\n\nhere()\n\n[1] \"C:/Users/Leonel/Desktop/MSDA/MS Data Analytics/Current Class/DA 6833/Practicum 2 Github/leonelsalazar-P2-portfolio/starter-analysis-exercise\"\n\n# Read the CSV file\ndata &lt;- read.csv(here(\"Databystate.csv\"))\n\n\n# Select all columns except 3, 6, and 9\nData_Clean &lt;- dplyr::select(data, -c(3, 6, 9))\n\n\n# Output cleaned data file to a csv file.\n\nwrite.csv(Data_Clean, \"Data_Clean.csv\", row.names = FALSE)\n\n#write.csv(Data_Clean, \"C:/Users/ecruz/OneDrive/Documents/UTSA - Data Science Program/Semester Classes/Practicum II Repository/P2-Practicum-II-Portfolio-EdwardCruz/docs/Databystate_Clean.csv\")\n\n\n# Assuming your data frame is named \"data\"\n\n# Filter for rows where \"Loss\" or \"Deadout\" is present in any column (case-insensitive)\n\nlibrary(stringr)  # Load stringr package for regular expressions\ndata_filtered &lt;- Data_Clean[rowSums(sapply(data, grepl, pattern = c(\"Loss\"), ignore.case = TRUE)) &gt; 0, ]\n\n\n# Output cleaned data file to a csv file.\n\nwrite.csv(data_filtered, \"Data_Filtered.csv\", row.names = FALSE)\n\n#write.csv(Data_Clean, \"C:/Users/ecruz/OneDrive/Documents/UTSA - Data Science Program/Semester Classes/Practicum II Repository/P2-Practicum-II-Portfolio-EdwardCruz/docs/Databystate_Filtered.csv\")\n\n\n# View data str to see what class they are.\n\nstr(data_filtered)\n\n'data.frame':   718 obs. of  6 variables:\n $ Year      : int  2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 ...\n $ Period    : chr  \"JAN THRU MAR\" \"JAN THRU MAR\" \"JAN THRU MAR\" \"JAN THRU MAR\" ...\n $ State     : chr  \"ALABAMA\" \"ARIZONA\" \"ARKANSAS\" \"CALIFORNIA\" ...\n $ State.ANSI: int  1 4 5 6 8 9 12 13 15 16 ...\n $ Data.Item : chr  \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" ...\n $ Value     : chr  \"250\" \"2,600\" \"180\" \"19,000\" ...\n\n\n\nstr(data_filtered)\n\n'data.frame':   718 obs. of  6 variables:\n $ Year      : int  2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 ...\n $ Period    : chr  \"JAN THRU MAR\" \"JAN THRU MAR\" \"JAN THRU MAR\" \"JAN THRU MAR\" ...\n $ State     : chr  \"ALABAMA\" \"ARIZONA\" \"ARKANSAS\" \"CALIFORNIA\" ...\n $ State.ANSI: int  1 4 5 6 8 9 12 13 15 16 ...\n $ Data.Item : chr  \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" \"LOSS, COLONY COLLAPSE DISORDER\" ...\n $ Value     : chr  \"250\" \"2,600\" \"180\" \"19,000\" ...\n\n# Load the dataset\ndata_filtered &lt;- read.csv(here::here(\"Data_Filtered.csv\"), stringsAsFactors = FALSE)\n\n# Convert 'Value' to numeric\ndata_filtered$Value &lt;- as.numeric(gsub(\",\", \"\", data_filtered$Value))\n\n# Handle missing values by replacing NAs with the median value\ndata_filtered$Value[is.na(data_filtered$Value)] &lt;- median(data_filtered$Value, na.rm = TRUE)\n\n# Boxplot of Value by Year and Data.Item\nggplot(data_filtered, aes(x = factor(Year), y = Value, fill = Data.Item)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_y_continuous(labels = comma) +\n  labs(title = \"Boxplot of Value by Year and Data.Item\", x = \"Year\", y = \"Value\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Scatterplot of Value by State.ANSI\nggplot(data_filtered, aes(x = State.ANSI, y = Value, color = factor(Year))) +\n  geom_point() +\n  labs(title = \"Scatterplot of Value by State.ANSI\", x = \"State.ANSI\", y = \"Value\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load necessary library\nlibrary(scales)\n\n\n# Assuming data_filtered is already loaded and has the required columns\n\n# Create the plot\np &lt;- ggplot(data_filtered, aes(x = Period, y = Value, fill = Data.Item)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_y_continuous(labels = comma) +\n  labs(title = \"Boxplot of Value by Period and Data.Item\", x = \"Period\", y = \"Value\")\n\n# Print the plot\nprint(p)\n\n\n\n\n\n\n\n\n************** Leo provided additional code below and works perfectly********************\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(reshape2)\n\nWarning: package 'reshape2' was built under R version 4.3.3\n\n\n\nAttaching package: 'reshape2'\n\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n\nlibrary(cluster)\n\n\nAttaching package: 'cluster'\n\n\nThe following object is masked from 'package:maps':\n\n    votes.repub\n\nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nlibrary(factoextra)\n\nWarning: package 'factoextra' was built under R version 4.3.3\n\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\nWarning: package 'rpart.plot' was built under R version 4.3.3\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.3.3\n\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\nlibrary(e1071)\n\nWarning: package 'e1071' was built under R version 4.3.3\n\n\n\n# Load your dataset\n# Assuming your data frame is named 'data_hcny'\n\ndata_hcny &lt;- read.csv(here(\"hcny_CleanDraft.csv\"))\n\n\ndata_clean &lt;- na.omit(data_hcny)\n\n\n# Descriptive Statistics\nprint(\"Descriptive Statistics:\")\n\n[1] \"Descriptive Statistics:\"\n\nsummary(data_clean)\n\n    state            varroa_mites    other_pests       disease      \n Length:11          Min.   : 8.00   Min.   : 1.70   Min.   : 0.100  \n Class :character   1st Qu.:13.45   1st Qu.: 3.20   1st Qu.: 0.750  \n Mode  :character   Median :26.80   Median : 6.40   Median : 1.000  \n                    Mean   :32.41   Mean   :11.55   Mean   : 6.718  \n                    3rd Qu.:48.85   3rd Qu.:11.85   3rd Qu.: 4.600  \n                    Max.   :67.20   Max.   :42.30   Max.   :47.800  \n   pesticides        other          unknown      \n Min.   : 0.50   Min.   : 0.50   Min.   : 1.100  \n 1st Qu.: 1.70   1st Qu.: 1.05   1st Qu.: 2.900  \n Median : 5.70   Median : 3.40   Median : 4.400  \n Mean   :10.34   Mean   :10.51   Mean   : 8.718  \n 3rd Qu.:11.30   3rd Qu.:11.35   3rd Qu.: 8.100  \n Max.   :49.20   Max.   :48.10   Max.   :46.800  \n\n\n\n# Visualizations\n\n# Bar Plot for varroa_mites by State\nggplot(data_clean, aes(x = state, y = varroa_mites)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Varroa Mites by State\", y = \"Percentage\", x = \"State\")\n\n\n\n\n\n\n\n\n\n# Stacked Bar Plot\ndata_long &lt;- data_clean %&gt;%\n  gather(key = \"factor\", value = \"percentage\", -state)\n\nggplot(data_long, aes(x = state, y = percentage, fill = factor)) +\n  geom_bar(stat = \"identity\") +\n theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Factors Affecting Bees by State\", y = \"Percentage\", x = \"State\")\n\n\n\n\n\n\n\n\n\n# Heatmap\ndata_melt &lt;- melt(data_clean, id.vars = \"state\")\n\nggplot(data_melt, aes(x = variable, y = state, fill = value)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"red\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Heatmap of Factors Affecting Bees\", y = \"State\", x = \"Factor\")\n\n\n\n\n\n\n\n\n\n# Pie Chart for the United States\nus_data &lt;- data_clean %&gt;%\n  filter(state == \"United States\") %&gt;%\n  dplyr::select(-state) %&gt;%\n  gather(key = \"factor\", value = \"percentage\")\n\nggplot(us_data, aes(x = \"\", y = percentage, fill = factor)) +\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\") +\n  theme_void() +\n  labs(title = \"Distribution of Factors Affecting Bees in the United States\")\n\n\n\n\n\n\n\n\n\n# Correlation Analysis\ncor_data &lt;- cor(data_clean[,-1])\nprint(\"Correlation Matrix:\")\n\n[1] \"Correlation Matrix:\"\n\nprint(cor_data)\n\n             varroa_mites other_pests   disease pesticides     other    unknown\nvarroa_mites    1.0000000  0.62115999 0.5907042 0.65228365 0.6085037 0.55340334\nother_pests     0.6211600  1.00000000 0.1180091 0.06810399 0.3449221 0.05806591\ndisease         0.5907042  0.11800909 1.0000000 0.90369098 0.9194785 0.97833233\npesticides      0.6522836  0.06810399 0.9036910 1.00000000 0.8235853 0.86362322\nother           0.6085037  0.34492207 0.9194785 0.82358532 1.0000000 0.86993151\nunknown         0.5534033  0.05806591 0.9783323 0.86362322 0.8699315 1.00000000\n\n\n\n# Assumption Checks for Descriptive Analysis\nprint(\"Assumption Checks:\")\n\n[1] \"Assumption Checks:\"\n\n\n\n# Normality check\nshapiro_results &lt;- lapply(data_clean[-1], function(column) shapiro.test(column))\nprint(\"Shapiro-Wilk Test for Normality:\")\n\n[1] \"Shapiro-Wilk Test for Normality:\"\n\nprint(shapiro_results)\n\n$varroa_mites\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.87839, p-value = 0.09925\n\n\n$other_pests\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.72499, p-value = 0.0009831\n\n\n$disease\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.51395, p-value = 2.235e-06\n\n\n$pesticides\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.70512, p-value = 0.0005444\n\n\n$other\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.70797, p-value = 0.0005924\n\n\n$unknown\n\n    Shapiro-Wilk normality test\n\ndata:  column\nW = 0.55542, p-value = 7.156e-06\n\n\n\n# Homogeneity of variances\n\nlevene_results &lt;- leveneTest(varroa_mites ~ state, data = data_clean)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\nprint(\"Levene's Test for Homogeneity of Variances:\")\n\n[1] \"Levene's Test for Homogeneity of Variances:\"\n\nprint(levene_results)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup 10     NaN    NaN\n       0               \n\n\n\n# Cluster Analysis\ndata_cluster &lt;- data_clean %&gt;%\n  filter(state != \"United States\") %&gt;%\n  dplyr::select(-state)\n\nhc &lt;- hclust(dist(data_cluster), method = \"complete\")\nplot(hc, labels = data_clean$state[data_clean$state != \"United States\"], main = \"Hierarchical Clustering of States\")\n\n\n\n\n\n\n\n\n\n# Principal Component Analysis (PCA)\ndata_pca &lt;- data_clean %&gt;%\n  filter(state != \"United States\") %&gt;%\n  dplyr::select(-state) %&gt;%\n  scale()\n\n\npca_result &lt;- prcomp(data_pca, center = TRUE, scale. = TRUE)\nsummary(pca_result)\n\nImportance of components:\n                          PC1    PC2    PC3     PC4     PC5     PC6\nStandard deviation     2.0647 1.1246 0.5666 0.34369 0.15432 0.09672\nProportion of Variance 0.7105 0.2108 0.0535 0.01969 0.00397 0.00156\nCumulative Proportion  0.7105 0.9213 0.9748 0.99447 0.99844 1.00000\n\n\n\nfviz_pca_var(pca_result, col.var = \"contrib\", gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"))\n\n\n\n\n\n\n\n\n\n# Support Vector Machine (SVM)\nsvm_model &lt;- svm(varroa_mites ~ other_pests + disease + pesticides + other + unknown, data = data_clean)\nsummary(svm_model)\n\n\nCall:\nsvm(formula = varroa_mites ~ other_pests + disease + pesticides + \n    other + unknown, data = data_clean)\n\n\nParameters:\n   SVM-Type:  eps-regression \n SVM-Kernel:  radial \n       cost:  1 \n      gamma:  0.2 \n    epsilon:  0.1 \n\n\nNumber of Support Vectors:  10\n\n\n\n# Assuming predictions and data_clean$varroa_mites are already created\n\n# Example data\ndata_clean &lt;- data.frame(\n  varroa_mites = c(5, 10, 15, 20),\n  other_variable = c(2, 4, 6, 8)\n)\n\n# Fit a linear model\nmodel &lt;- lm(varroa_mites ~ other_variable, data = data_clean)\n\n# Generate predictions\npredictions &lt;- predict(model, newdata = data_clean)\n\n\n# Plot the data\nplot(predictions, data_clean$varroa_mites, \n     xlab = \"Predictions\", \n     ylab = \"Varroa Mites\", \n     main = \"Predictions vs Varroa Mites\",\n     las = 1, # makes y-axis labels horizontal\n     cex.lab = 1.2, # increases axis labels size\n     cex.axis = 1.2) # increases tick labels size\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Write the cleaned data to a new CSV file\n\n\n# Assuming your dataset is named data_hcny\ndata_hcny_clean &lt;- data_hcny %&gt;% drop_na()\n\n\nwrite.csv(data_hcny_clean, here(\"hcnydata_cleaned.csv\"), row.names = FALSE)\n\nVarroa Mite"
  },
  {
    "objectID": "manuscript_final-2.html#statistical-analysis",
    "href": "manuscript_final-2.html#statistical-analysis",
    "title": "Untitled",
    "section": "Statistical analysis",
    "text": "Statistical analysis\nExplain anything related to your statistical analyses."
  },
  {
    "objectID": "manuscript_final-2.html#exploratorydescriptive-analysis",
    "href": "manuscript_final-2.html#exploratorydescriptive-analysis",
    "title": "Untitled",
    "section": "Exploratory/Descriptive analysis",
    "text": "Exploratory/Descriptive analysis\nUse a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.\n?@tbl-summarytable shows a summary of the data.\nNote the loading of the data providing a relative path using the ../../ notation. (Two dots means a folder up). You never want to specify an absolute path like C:\\ahandel\\myproject\\results\\ because if you share this with someone, it won’t work for them since they don’t have that path. You can also use the here R package to create paths. See examples of that below. I generally recommend the here package.\n\n# Install necessary packages\n#install.packages(\"DiagrammeR\")\n\n# Load the DiagrammeR package\nlibrary(DiagrammeR)\n\nWarning: package 'DiagrammeR' was built under R version 4.3.3\n\n# Create the flowchart using DiagrammeR\ngrViz(\"\n  digraph Data_Analysis_Flowchart {\n    graph [layout = dot, rankdir = TB]\n\n    node [shape = box, style = filled, color = lightblue]\n    \n    Define_Objectives [label = 'Define Objectives']\n    Collect_Data [label = 'Collect Data']\n    Clean_Data [label = 'Clean Data']\n    Analyze_Data [label = 'Analyze Data']\n    Interpret_Results [label = 'Interpret Results']\n    Visualize_Data [label = 'Visualize Data']\n    Compile_Report [label = 'Compile Report']\n    Review_Revise [label = 'Review & Revise']\n    Present_Report [label = 'Present Report']\n\n    Define_Objectives -&gt; Collect_Data\n    Collect_Data -&gt; Clean_Data\n    Clean_Data -&gt; Analyze_Data\n    Analyze_Data -&gt; Interpret_Results\n    Interpret_Results -&gt; Visualize_Data\n    Visualize_Data -&gt; Compile_Report\n    Compile_Report -&gt; Review_Revise\n    Review_Revise -&gt; Present_Report\n  }\n\")"
  },
  {
    "objectID": "manuscript_final-2.html#summary-and-interpretation",
    "href": "manuscript_final-2.html#summary-and-interpretation",
    "title": "Untitled",
    "section": "Summary and Interpretation",
    "text": "Summary and Interpretation\nSummarize what you did, what you found and what it means."
  },
  {
    "objectID": "manuscript_final-2.html#strengths-and-limitations",
    "href": "manuscript_final-2.html#strengths-and-limitations",
    "title": "Untitled",
    "section": "Strengths and Limitations",
    "text": "Strengths and Limitations\nDiscuss what you perceive as strengths and limitations of your analysis."
  },
  {
    "objectID": "manuscript_final-2.html#conclusions",
    "href": "manuscript_final-2.html#conclusions",
    "title": "Untitled",
    "section": "Conclusions",
    "text": "Conclusions\nWhat are the main take-home messages?\nInclude citations in your Rmd file using bibtex, the list of references will automatically be placed at the end\nThis paper [@leek2015] discusses types of analyses.\nThese papers [@mckay2020; @mckay2020a] are good examples of papers published using a fully reproducible setup similar to the one shown in this template.\nNote that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal are available. You also specify the location of your bibtex reference file in the YAML. You can call your reference file anything you like."
  }
]